# JAX implementation of BART

This project is a JAX implementation of [BART](https://arxiv.org/abs/1910.13461). The aim of this project is to demonstrate how Transformer-based models can be implemented using JAX and trained on Google Cloud TPUs.

This project is supported by Cloud TPUs from Google's [TPU Research Cloud](https://sites.research.google/trc/about/) (TRC).

This project is inspired by [hyunwoongko/transformer](https://github.com/hyunwoongko/transformer), while the code for this project is entirely written by myself.
